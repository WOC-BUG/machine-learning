# 5.6深度学习

## 概念
* 一般的，复杂模型的训练效率较低，易陷入过拟合。计算能力的大幅提升可缓解训练低效性，训练数据的大幅增加可降低过拟合风险。
* 典型的深度学习模型，就是很深层的神经网络。
* 增加隐层数目可有效提高容量，然而多隐层神经网络难以直接用经典算法进行训练，因为误差在多隐层内逆传播时，往往会“发散”(diverge)而不能收敛到稳定状态。


## 无监督层训练(unsupervised layer-wise training)
![avatar](\无监督层训练.png)

## 权共享(weight sharing)
让一组神经元使用相同的连接权

### 例：以CNN进行手写数字识别
![avatar](\CNN用于手写数字识别.png)

**输入：** $32*32$的手写数字图像
**输出：** 识别结果
**卷积层&采样层：** 对输入信号进行加工，每个卷积层包含多个特征映射
**采样层：** 基于局部相关性原理进行亚采样，从而在减少数据量的同时保留有用信息
**连接层：** 实现与输出目标之间的映射
**特征映射：** 是$28*28$的神经元阵列，每个神经元负责从$5*5$的区域通过卷积滤波器提取局部特征

CNN可用BP算法进行训练，但在训练中，无论是卷积层还是采样层，其每一组神经元都是用相同的连接权，从而答复减少了需要训练的参数数目